---
title: "NetworkGraphs"
author:
- name: Catherine E. Laing
  affiliation: '1'
  corresponding: yes
  address: Department of Language and Linguistic Science, University of York, Heslington, YO10 5DD.
  email: catherine.laing@york.ac.uk
authornote: |
 All code and associated data for this manuscript can be found at https://github.com/cathelaing/NetworkGraphs.
shorttitle: Network graphs of early phonological development
output:
  papaja::apa6_pdf: default
  #extra_dependencies: ["float"]
  #papaja::apa6_word: default
abstract: "ADD."
keywords: systematicity, phonological development, preferential attachment, networks analysis
#wordcount: "" 
bibliography: Systematicity.bib
#floatsintext: yes
figsintext: no
figurelist: yes
tablelist: no
footnotelist: no
linenumbers: no
numbersections: false
mask: no
draft: no
documentclass: apa6
header-includes:
-  \DeclareDelayedFloatFlavor{kableExtra}{table}
- \usepackage{tipa}
#- \newfontfamily\PF{Arial}
classoption: man
affiliation:
- id: '1'
  institution: University of York, York, UK
latex_engine: xelatex
---

```{r setup, include=FALSE}

source("prelims.R")
r_refs(file="r-references.bib")


my_citations <- cite_r(
  file="r-references.bib"
  , pkgs=c("tidyverse", "igraph", "papaja", "lmerTest")
  , withhold=FALSE
  , footnote=TRUE
)

# load files

SWD_red <- globalsmallworlddata[which(complete.cases(globalsmallworlddata[
  ,c('path_length', 'clust_coef_global', 'clust_coef_avg', 'mean_k')])),]

stat_sum_df <- function(fun, geom="crossbar", ...) {
  stat_summary(fun.data=fun, colour="red", geom=geom, width=0.2, ...)
}

```

Infants' early words are phonologically similar to one another, if not in the vocabulary items they choose to produce, but in the way they produce them. This has been well-documented in a number of case studies [refs], and can be clearly observed in datasets of early productions. For example, Deuchar and Quay's [ref] record of their Spanish-English bilingual child's vocabulary acquisition shows that many of her earliest words are produced with an open CV syllable, and she produces a number of identical forms to refer to a range of different (though phonologically-similar) words. This suggests that infants may be drawing on a systematic approach to early productions, whereby a small subset of simple phonological forms are used to produce a range of more varied and phonologically-challenging adult targets. This paper will consider this systematicity from a networks perspective, drawing on network graphs of the early vocabulary to determine how similar infants' words are to one another, and how this changes over time. Network analysis is an increasingly popular method of analysing lexical acquisition. Network models allow the analysis of connectivity within a system (in our case, the lexical or phonological system), and can track how that connectivity changes over time. In the case of language development, the nodes (individual items) in the network typically consist of words, and these are connected (or not) depending on how similar two nodes are in phonological or semantic space. Because this is a convenient way to think about language development over time, a number of studies have considered vocabulary acquisition within this framework. Analyses have considered infants acquiring their first language [] and adults acquiring a novel language []. 

Systematicity in early phonological development is most comprehensively discussed in work by Vihman [REFs]. In more than four decades of work incorporating data from hundreds of infants acquiring an impressive range of languages, Vihman demonstrates a clear systematicity in infants' path to target-like word production. From the initial 'surprisingly accurate' [ref?] forms that appear in the first stages of word production, infants are shown to draw on what they know: they generally choose, for first production, words that are simple in their target phonological form, with consonants that are already familiar from the most common syllables of canonical babble [@mccune_early_2001]. These forms are, in Vihman's terms, *selected* for first word production owing to their easily-producible features. As the vocabulary grows, infant must necessarily acquire forms that do not contain such accessible phonological or segmental properties. Here we begin to see regression in the accuracy of early production, as infants systematically adapt forms to fit the most common structures and segments in their repertoire. When words are systematically altered to fit an evidently dominant pattern in the child's output, these forms are said to be *adapted*. That is, systematicity is apparent not just in the earliest words, but across the trajectory of acquisition as infants deal with the challenges of early word production by relying on well-rehearsed output forms. That is, over the first months of lexical development at least, infants' productions of newly-acquired words are likely to match their productions of existing words in the lexicon.

In previous work [Laing, under review], I draw on network analysis to show that in the first three years of life, infants' production of new words can be predicted based on the words they already produce. That is, a word is more likely to be acquired if it is phonologically similar to highly-connected existing words in the productive repertoire, or words that cluster together as phonologically-similar forms. This effect becomes stronger over time, suggesting that systematicity is more relevant to later word learning (at least, upto age 30 months) than in the first few months of word production. This reflects the systematicity that has been well-documented in previous studies [refs]. Moreover, the phonological properties of infants' word productions are more similar to one another than their adult target forms would suggest. Looking at other similar studies, reveals some support for these results, as well as some inconsistencies in approaches and subsequent findings. Laing [ref] drew on corpus data of fortnightly word production across nine infants; similar results have been observed by Kalinowski et al [in prep], who draw on vocabulary norms from >1000 Norwegian infants taken longitudinally at upto six individual time-points. Systematicity was also identified in early word learning by Siew and Vitevitch [ref], in an analysis of vocabulary norms of children aged 3-9 years acquiring English and Dutch. On the other hand, Fourtassi and colleagues [] analysed productive vocabulary norms for infants aged 16-30 acquiring a range of 10 languages, to find that acquisition of newly-acquired words was not predicted by the phonological form of previously-acquired words (based on assumptions made by vocabulary norming data). Instead, the connectivity of the *external* network was more likely to inform word learning: phonologically-similar words in the input were a better predictor of learning than highly-connected known words. However, as pointed out in Laing [] and Kalinowski et al. [], this study, and that of Siew and Vitevitch [], did not analyse the same infants over a range of time-points, meaning that it may not have been possible to capture phonological systematicity in this data.

This previous work reported above uses network growth algorithms to test whether learning can be predicted based on the words that infants already know or produce. This method works on the assumption that, if infants' early word acquisition and production is phonologically systematic, then it should be possible to predict learning based on the known words in the infant's existing lexicon. Network growth models present a compelling computational approach to observing systematicity in the developing lexicon, but they don't give us a clear view into the extent to which early-acquired forms are produced in a phonologically similar way. That is, network growth models analyse connectivity (are two words similar, yes or no? if yes then they are connected in the network), rather than phonological distance (*how* similar are two words in the network?). This study expands on previous work, and builds on findings from Laing [UR], by analysing network graphs of infants' early lexicons. This provides an insight into the properties of the network, including how densely-connected the network is, and the phonological distance between items in the network. It also allows us to make predictions about network properties over time that reflect word selection and adaptation. Following Laing [UR], this paper will analyse infants' actual productions as well as the adult target forms, to test the extent to which systematicity is present in production, in terms of both the words infants select in early development, and how they produce them. 

# Research questions and predictions

Using network graphs instead of growth algorithms to look more closely at the phonological distance between individual words in the developing lexicon, this paper addresses the following two questions:

1. How systematic are early word productions, and (how) does this change over time?
2. Are the phases of word selection and adaptation identifiable in the dataset?

To test these questions, network graphs will be generated using the *igraph()* package [@R-igraph] in R [@R-base]. To address the first question, properties of the graphs will be analysed to determine 1) how closely connected individual words are to one another; 2) how dense the overall distribution of words is in the network; and 3) how this changes over time. Following Vihman's work, and findings presented by Laing [UR], it is expected that the early vocabulary will become increasingly systematic over time. This would be reflected in denser clusters of phonologically-similar forms and lower distance between words. Simulated networks will be used to compare the real networks against highly systematic and random networks to determine the extent of systemacitity present in the data.

To address the second question, network graphs of infants' actual productions will be compared with those of the target form, to trace the 'target-likeness' of individual productions, and how this changes over time. Following Vihman once again, early word selection would be reflected in early similarities between Actual and Target network properties, as target forms are selected to match the structures and segments that infants are able to produce. Over time, Actual and Target forms are expected to diverge, such that Actual forms show more systematicity in the data than Target forms. Later on in the data, we may see the two come back together as novel words are produced in an increasingly target-like way, though note that this would contradict the prediction made above regarding increasing systematicity with age. Approaches used to test these predictions are outlined in detail below.


# Methods

## Data extraction and preparation

This study draws on the same data as that analysed by Laing [UR]. This was drawn from two corpora on PhonBank (https://phonbank.talkbank.org/): Providence [American English, @demuth_word-minimality_2006] and Lyon [French, @demuth_katherine_prosodically-conditioned_2008]. These were selected due to their equivalent data collection methods and the fact that the infants' productions, as well as the corresponding target forms, are phonetically transcribed. Nine infants' (5 English, 4 French, 4 boys overall) data were extracted using Phon [@hedlund_gregory_phon_2020], from the transcript with their first-recorded word to the final transcript taken at age 2;6. Infants were recorded in the home on a fortnightly basis, participating in naturalistic interactions with their caregivers. Two of the American infants were recorded weekly during some periods of data collection, but this is not an issue for this analysis since no between-child comparisons will be made. See Demuth et al. [-@demuth_word-minimality_2006] and Demuth and Tremblay [-@demuth_katherine_prosodically-conditioned_2008] for full details of data collection.

Extracted data was filtered to include only words featuring on the communicative development inventory (CDI) of the respective language, including all variants of a given form. For example, plurals were included alongside the singular noun form, and variable verb conjugations alongside their corresponding infinitive verb form. These data were used to create a network for each infant, whereby all words in a given month that hadn't been produced in previous months were included as new items in the network. When a word had been produced in previous months, it was not included. While this means that the data does not capture change in the production of a single form over time, it allows us to observe network growth at the point of acquisition for each word form. 

To determine the structure of the network, the first step was to create distance values between each word and each other word in the network. This was first done using a 'global' network of all forms produced by the infant up to the final session at 2;6, to create a large distance matrix for each infant that incorporated all word productions. Distance values were established using methods set out in Monaghan et al. [-@monaghan_measures_2010], using distinctive features to generate a set of phonetic values for each word that could then be compared with all other words (note that only consonants were analysed, given that vowels are highly variable in early production and also very difficult to transcribe accurately; [@donegan_normal_2013; @kent_what_2020]). Euclidean distance between the values of each word and each other word in each infant's global network was then used to determine how close/distant words were from one another. Often, infants produced multiple tokens of the same word type in a given month, often with high variability across tokens. Because it was not possible to generate networks with all tokens included (even with only single word types included, the final dataset for all nine infants includes over 5.5 million data points, once distance between each word and each other word is calculated), a mean value for each distinctive feature was established across tokens, meaning that each word's distinctive feature value represents the variability of the infant's production of a given word. This may not be a perfect measure, but it is more representative than taking, for example, the first instance of each word type.

Distance scores were generated between each word and each other word in each child's dataset, for both Target and Actual forms. These scores were then normalised, and a normalised distance of 0.25 was chosen to indicate connectivity. That is, words were said to be connected in the network if their distance score was ≤0.25. This accounted for the lower quartile of connectivity across the dataset. See Supplementary Materials for an overview of how this measure was established.

```{r data overview}
types.corpus <- comparison_data %>%
  group_by(corpus, Speaker) %>%
  distinct(Gloss, .keep_all=T) %>%
  tally() %>% summarise(n=sum(n))

types <- comparison_data %>%
  group_by(Speaker) %>%
  distinct(Gloss, .keep_all=T) %>%
  tally() %>% summarise(n=sum(n))

tokens <- comparison_data %>%
  group_by(Gloss, Speaker) %>%
  tally() %>% ungroup() %>%
  summarise(mean_tok=mean(n),
            sd_tok=sd(n))

tokens.corpus <- comparison_data %>%
  group_by(Gloss, Speaker, corpus) %>%
  tally() %>% ungroup() %>%
  group_by(corpus) %>%
  summarise(mean_tok=mean(n),
            sd_tok=sd(n))

```

The final dataset includes `r round(types$n)` word types in total, with `r round(subset(types.corpus, corpus == "English")$n)` in the English corpus and `r round(subset(types.corpus, corpus == "French")$n)`) in the French corpus. On average, infants produced `r round(tokens$mean_tok)` tokens of each word type in a single session (SD = `r round(tokens$sd_tok)`; mean English = `r round(subset(tokens.corpus, corpus == "English")$mean_tok)`, SD = `r round(subset(tokens.corpus, corpus == "English")$sd_tok)`; mean French = `r round(subset(tokens.corpus, corpus == "French")$mean_tok)`, SD = `r round(subset(tokens.corpus, corpus == "French")$sd_tok)`). 

## Data analysis

### Network graphs

The prepared data was then used to generate a series of network graphs for each infant (for both Target and Actual data) using the *igraph()* package in R [@R-igraph]. One network was generated per month, for each month in the dataset, based on all words produced in the given month and all months prior. The network at time-point *n*+1 thus included all words at time-point *n*, plus all additional words produced for the first time at *n*+1. The *igraph()* package generates graphs that include all nodes (whether or not they are connected to other nodes[^1]), and measures the distance between all connected nodes, as well as the clustering of nodes in graphical space. 

[^1]: Recall that any two nodes that have a scaled phonological distance of >.25 will not be connected.

Two key variables will be explored through an analysis of network graphs: *mean path length* and *clustering coefficient*. Path length is a measure of distance between nodes, and mean path length indexes the average connectivity (of all connected nodes) within a network; by this measure, we would expect that systematicity in early phonological development would be reflected in low mean path length. Clustering coefficient is an indication of network density: a higher density of nodes in the network indicates denser clusters of similar forms; again, this is what we would expect to see in a network of early phonological development. See Goldbeck [-@golbeck_analyzing_2013] for a full overview of network structures and measures.

### Simulated networks

PAT-like networks should exhibit properties of prototypical "small-world" network growth, namely a low mean path length and a high clustering coefficient [@watts_collective_1998; @amaral_classes_2011; @steyvers_large-scale_2005]: words should be more densely connected, with shorter connections between words. To test this, mean path length and clustering coefficient values were generated for both the Target and Actual networks, as outlined below. Data were compared to the growth of a simulated small-world network, known as a Watts-Strogatz network [@watts_collective_1998]; if no statistical differences are observed between the real and simulated data over the trajectory of development, this would reflect strong systematicity in growth of the real network. The real data were also compared to a similarly-sized but randomly-generated network known as a Erdős–Rényi model. Similarly, if the real network grows in a systematic way, then we would expect the real data to differ significantly from the randomly-generated Erdős–Rényi network. To run these analyses, mean path length and clustering coefficient were calculated for each monthly graph, and then compared to the two kinds of simulated data, matched for network size: a Watts-Strogatz network (prototypical systematic network) and an Erdős–Rényi network (random network). Watts-Strogatz simulations were generated to match both the mean connectivity and the network size of the network in each month; Erdős–Rényi networks require only network size to be specified.

# Results

## RQ1: How systematic are early word productions, and (how) does this change over time?

To test RQ1, network graphs were compared to simulated small world and random networks of equivalent size to determine whether the data (the *Real* network) differed from the *Simulated* networks. Recall that systematic network growth, as predicted here, should reflect a small-world network growth structure. Two key components of these networks were compared: mean path length and clustering coefficient. Small-world networks typically have a low mean path length and a high clustering coefficient; for both measures we would expect the Real data to differ significantly from the Simulated Erdős–Rényi (random) network, and for the Real network to show similar properties to the Simulated Watts-Strogatz (small-world) network. Note that the extent of the expected statistical difference is not easy to predict here: if the Real network is very similar to the Watts-Strogatz network then no statistical difference would be expected, but this relies on the Real data being highly systematic, which may not be realistic. In order to fully understand the nature of the data, figures and model outputs will be inspected in relation to these predictions.

The two measures will be discussed in turn. Models include mean path length or average clustering coefficient as dependent variables, respectively, each with data type (Real vs. small-world vs. random), corpus (English vs. French) and age as fixed effects, and subject as a random effect with a by-subject random slope for the effect of age. Initial model comparisons showed that including network size to the model improved fit for the clustering coefficient data, but not for mean path length, so an age*network size interaction was included in this model only. 

### Mean Path Length
Mean path length was calculated for each child's monthly networks using the *igraph()* package in R [@R-igraph]. Equivalent-sized Watts-Strogatz and Erdős–Rényi networks were generated for comparison.  

```{r mean path length, message=FALSE, warning=FALSE, include=FALSE}

MPL <- lmerTest::lmer(path_length ~ data_type + corpus + age + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "WS_actual", "Erdos_Renyi")
                                                           ),
                                       REML=FALSE)
#summary(MPL)

MPL.0 <- lmerTest::lmer(path_length ~ corpus + age + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "WS_actual", "Erdos_Renyi")
                                                           ),
                                       REML=FALSE)

MPL_anova <- anova(MPL, MPL.0)

MPL_df <- MPL_anova$Df[2]
MPL_chisq <- MPL_anova$Chisq[2]
MPL_p.value <- MPL_anova$`Pr(>Chisq)`[2]


```

Nested model comparisons revealed a significant effect for data type on mean path length. See Table \@ref(tab:table-model-output). As shown in Table \@ref(tab:table-real-sim), the Real data had a significantly lower mean path length than the random Simulated data, as predicted. However, the Real data also differed significantly from the small-world Simulated data, which had a significantly shorter mean path length than that of the Real data. Model outputs revealed no effect for corpus or age on the data. COntrary to preductions, there was no change in systematicity over time, at least in terms of mean distance between words. 

```{r clustering coefficient, message=FALSE, warning=FALSE, include=FALSE}

CC <- lmerTest::lmer(clust_coef_avg ~ data_type + corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "WS_actual", "Erdos_Renyi")
                                                           ),
                                       REML=FALSE)
#summary(CC)

CC.0 <- lmerTest::lmer(clust_coef_avg ~ corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "WS_actual", "Erdos_Renyi")
                                                           ),
                                       REML=FALSE)

CC_anova <- anova(CC, CC.0)

CC_df <- CC_anova$Df[2]
CC_chisq <- CC_anova$Chisq[2]
CC_p.value <- CC_anova$`Pr(>Chisq)`[2]

model.summary.CC <- summary(CC)

beta.val.interaction <- model.summary.CC$coefficients %>% 
  as.data.frame %>% 
  tibble::rownames_to_column("Effect") %>%
  filter(Effect == "age:numNodes")

CC_tab <- model.summary.CC$coefficients %>%
  as.data.frame %>%
  rename(
    "beta"="Estimate"
     , "SE"="Std. Error"
     , "t"="t value"
     , "p"="Pr(>|t|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  ) %>%
  printnum(
    digits=c(3, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  #select(Effect, `beta`, `SE`, `t`, `p`) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `t`=as.numeric(`t`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p)) %>%
  mutate(Effect = fct_recode(Effect,
                             "Real vs. Watts-Strogatz" = "Data typeWS actual",
                             "Real vs. Erdős–Rényi" = "Data typeErdos Renyi",
                             "Corpus" = "CorpusFrench",
                             "Network size" = "NumNodes",
                             "Age * Network size" = "Age $\\times$ NumNodes")) %>%
  dplyr::select(Effect, beta, SE, t, p)

```

### Clustering coefficient
The same patterns were found when clustering coefficient was tested in the model. See Tables \@ref(tab:table-model-output) and \@ref(tab:table-real-sim). The Real data had a significantly higher clustering coefficient than the random Simulated data, but this was significantly lower than that of the small-world Simulated data. Again there was no effect for corpus on the data, and no effect of age in its own right, but network size, and its interaction with age, were found to be significant predictors of average clustering coefficient: clustering coefficient values decreased as network size increased, suggesting that systematicity became stronger in the data over time. The age * network size interaction was also found to be significant, such that with each additional month of age, the effect of network size on clustering coefficient decreased by `r round((beta.val.interaction$Estimate)*100,3)`%.

GOT TO HERE

### Actual vs. Target data
The unexpected differences between the Real data and the small-world Simulated data are difficult to interpret, given that there is no clear model of what phonological systematicity would look like in a small-world network. To further interrogate systematicity within the data, the Real (Actual) data was compared to the Real Target data. Target data serves as an appropriate proxy for connectivity and network properties within a phonological network, albeit a network that is constrained by words produced in early acquisition, and further constrained by the fact that only a subset of these (i.e. CDI words) are included in the dataset. Basic model structure was the same as reported above, but with only Real data (Actual vs. Target) considered as a fixed effect. Initial model comparisons supported the inclusion of an age * network size interaction in both sets of models.

```{r data type - mean path length, message=FALSE, warning=FALSE, include=FALSE}

MPL.DT <- lmerTest::lmer(path_length ~ data_type + corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "target")
                                                           ),
                                       REML=FALSE)
#summary(MPL.DT)

MPL.DT.0 <- lmerTest::lmer(path_length ~ corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "target")
                                                           ),
                                       REML=FALSE)

MPL.DT_anova <- anova(MPL.DT, MPL.DT.0)

MPL.DT_df <- MPL.DT_anova$Df[2]
MPL.DT_chisq <- MPL.DT_anova$Chisq[2]
MPL.DT_p.value <- MPL.DT_anova$`Pr(>Chisq)`[2]

```

There was a significant effect for data type on mean path length. Model outputs revealed that Target data had a significantly higher mean path length than Actual data. See Table XX. This time there was also a significant effect for corpus; French data had a higher mean path length than English data. Both age and network size significantly affected mean path length, which increased as age/network size increased. The age * network size interaction was also significant, but this time the effect was negative, such that the effect of network size on mean path length decreased by XX% with each additional month of age. 

```{r data type - clustering coefficient, message=FALSE, warning=FALSE, include=FALSE}

CC.DT <- lmerTest::lmer(clust_coef_avg ~ data_type + corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "target")
                                                           ),
                                       REML=FALSE)
#summary(CC.DT)

CC.DT.0 <- lmerTest::lmer(clust_coef_avg ~ corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "target")
                                                           ),
                                       REML=FALSE)

CC.DT_anova <- anova(CC.DT, CC.DT.0)

CC.DT_df <- CC.DT_anova$Df[2]
CC.DT_chisq <- CC.DT_anova$Chisq[2]
CC.DT_p.value <- CC.DT_anova$`Pr(>Chisq)`[2]


```

The effect of data type on clustering coefficient was also significant. Mean clustering coefficient was significantly lower in Target vs. Actual data. It was also lower in French compared with English data. Mean clustering coefficient decreased as age and network size increased (indicating increased systematicity over time); the age * network size interaction was significant, such that the effect of network size on clustering coefficient decreased by XX% with each additional month of age. 

```{r model outputs, include=FALSE}

table.model.output <- rbind(MPL_anova, MPL.DT_anova, CC_anova, CC.DT_anova) %>%
  rownames_to_column(var="Model") %>%
  filter(Chisq > 0) %>%
  rename(#"PA Df"="Df",
         #"PA Chisq"="Chisq",
         "p"=`Pr(>Chisq)`) %>%
  mutate(Model=fct_recode(Model,
                           "Mean Path Length (Real vs. Simulated)"="MPL",
                            "Clustering Coefficient (Real vs. Simulated)"="CC",
                            "Mean Path Length (Actual vs. Target)"="MPL.DT",
                            "Clustering Coefficient (Actual vs. Target)"="CC.DT"),
             p=scales::pvalue(p)) %>%
  dplyr::select(Model, `Df`, `Chisq`, `p`)

model.summary.MPL <- summary(MPL)

MPL_tab <- model.summary.MPL$coefficients %>%
  as.data.frame %>%
  rename(
    "beta"="Estimate"
     , "SE"="Std. Error"
     , "t"="t value"
     , "p"="Pr(>|t|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  ) %>%
  printnum(
    digits=c(3, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  #select(Effect, `beta`, `SE`, `t`, `p`) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `t`=as.numeric(`t`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p)) %>%
  mutate(Effect = fct_recode(Effect,
                             "Real vs. Watts-Strogatz" = "Data typeWS actual",
                             "Real vs. Erdős–Rényi" = "Data typeErdos Renyi",
                             "Corpus" = "CorpusFrench")) %>%
  dplyr::select(Effect, beta, SE, t, p)

add_data1 <- data.frame(Effect = "Network size", beta = NA, SE = NA, t = NA, p = NA, row.names = "added")
add_data2 <- data.frame(Effect = "Age * Network size", beta = NA, SE = NA, t = NA, p = NA, row.names = "added")

MPL_tab <- bind_rows(MPL_tab, add_data1, add_data2)


model.summary.MPL.DT <- summary(MPL.DT)

MPL.DT_tab <- model.summary.MPL.DT$coefficients %>%
  as.data.frame %>%
    rename(
    "beta"="Estimate"
     , "SE"="Std. Error"
     , "t"="t value"
     , "p"="Pr(>|t|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  ) %>%
  printnum(
    digits=c(3, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `t`=as.numeric(`t`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p)) %>%
  mutate(Effect = fct_recode(Effect,
                             "Actual vs. Target" = "Data typetarget",
                             "Real vs. Erdős–Rényi" = "Data typeErdos Renyi",
                             "Corpus" = "CorpusFrench",
                             "Network size" = "NumNodes",
                             "Age * Network size" = "Age $\\times$ NumNodes")) %>%
  dplyr::select(Effect, beta, SE, t, p)

model.summary.CC.DT <- summary(CC.DT)

CC.DT_tab <- model.summary.CC.DT$coefficients %>%
  as.data.frame %>%
    rename(
    "beta"="Estimate"
     , "SE"="Std. Error"
     , "t"="t value"
     , "p"="Pr(>|t|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  ) %>%
  printnum(
    digits=c(3, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `t`=as.numeric(`t`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p)) %>%
  mutate(Effect = fct_recode(Effect,
                             "Actual vs. Target" = "Data typetarget",
                             "Real vs. Erdős–Rényi" = "Data typeErdos Renyi",
                             "Corpus" = "CorpusFrench",
                             "Network size" = "NumNodes",
                             "Age * Network size" = "Age $\\times$ NumNodes"))%>%
  dplyr::select(Effect, beta, SE, t, p)


real_v_sim <- cbind(MPL_tab, CC_tab)
actual_v_target <- cbind(MPL.DT_tab, CC.DT_tab)

actual_v_target[6] <- NULL
real_v_sim[6] <- NULL


```

```{r table-model-output, echo=F, message=FALSE, warning=FALSE, comment=F, results="asis"}
cap="Outputs from nested model comparisons testing the effect of data type (Real vs. Simulated and Actual vs. Target on mean path length and clustering coefficient."
knitr::kable(table.model.output, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c") %>%
  kable_styling()%>%
  row_spec(4, hline_after=T)

```

```{r table-real-sim, echo=F, message=FALSE, warning=FALSE, comment=F, results="asis"}
cap="Outputs from linear regression models testing comparisons of Real vs. Simulated data on mean path length and clustering coefficient."
knitr::kable(real_v_sim, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c") %>%
  add_header_above(c(" "=1, "Mean path length"=4, "Clustering coefficient"=4)) %>%
    kable_styling()#%>%
  # row_spec(1, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(2, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(3, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(4, hline_after=T) %>%
  # row_spec(5, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(6, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(7, extra_latex_after = "\\cline{2-10}")
```

```{r table-actual-target, echo=F, message=FALSE, warning=FALSE, comment=F, results="asis"}
cap="Outputs from linear regression models testing comparisons of Actual vs. Target data on mean path length and clustering coefficient."
knitr::kable(actual_v_target, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c") %>%
  add_header_above(c(" "=1, "Mean path length"=4, "Clustering coefficient"=4)) %>%
    kable_styling()#%>%
  # row_spec(1, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(2, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(3, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(4, hline_after=T) %>%
  # row_spec(5, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(6, extra_latex_after = "\\cline{2-10}") %>%
  # row_spec(7, extra_latex_after = "\\cline{2-10}")
```

```{r Figure-path-length-DT, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE}
plot(path_length_plot_DT)
cap <- sprintf("Change in mean path length over time, in Actual vs. Target data. Coloured lines represent Data type; coloured bands represent 95%% CIs.")
```

```{r Figure-path-length-all, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE}
plot(path_length_plot)
cap <- sprintf("Change in mean path length over time, in Real data (Actual) compared with Simulated small-world (Watts-Strogatz) and random (Erdős–Rényi) networks. Coloured lines represent Data type; coloured bands represent 95%% CIs.")
```

```{r Figure-clust-coef-DT, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE}
#par(cex=1.2)
plot(clust_coef_plot_DT)
cap <- sprintf("Change in mean clustering coefficient over time, in Actual vs. Target data. Coloured lines represent Data type; coloured bands represent 95%% CIs.")
```

```{r Figure-clust-coef-all, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE}
plot(clust_coef_plot)
cap <- sprintf("Change in mean clustering coefficient over time, in Real data (Actual) compared with Simulated small-world (Watts-Strogatz) and random (Erdős–Rényi) networks. Coloured lines represent Data type; coloured bands represent 95%% CIs.")
```


2. Is there evidence of word selection and adaptation in the dataset?

- if we take actual=target as a proxy of word selection, and actual!=target as a proxy of adaptation, then we'd expect to see actual and target forms being more similar earlier on in development, and less similar later. Similarity == connectivity in the network, at varying degrees of E.

To test RQ2, the phonological distance between target and actual forms was taken as a proxy of word selection and adaptation. That is, if a word is produced in a target-like way (i.e. assumed to be selected[^1]), then the phonological distance between the Target form and the way it is produced (Actual form) should be low. The opposite is true for adapted forms, as we expect, by definition, a non-target-like production and thus a higher distance between Target and Actual form. Following Vihman's [REF] framework, we would thus expect low distance been Actual and Target forms earlier on in development, and higher distance later. To test this, I drew on generalized additive mixed effects models (GAMMs), since these allow the analysis of non-linear change over time, and can account for statistical differences between two non-linear trajectories of data that may differ in non-linear ways [REFs].

[^1]: though note that, while a selected form is, by definition, target-like in phonological form, a target-like form isn't necessarily a selected form.

First, generalised linear mixed effects models, or GAMMs, were used to examine connectivity of the infants' Actual and Target networks and how these changed over time. These were run using the *mgcv()* package in R [REF]. These models reveal the extent to which the two networks differ (or not) from one another across infants, and how this changes non-linearly month-by-month. Fixed effects in the model can include parametric terms, as is typical in regression modelling, and also *smooth terms*, or non-linear fixed effects. Much like mixed-effects linear models, GAMMs can account for random effects in the data; in this case by-subject random effects were included through the addition of *random smooths* in the model.

The model tested number of connections (*mean k*) as the dependent variable, working on the assumption that connectivity in the networks would be similar during periods of word selection, and would differ during periods of adaptation. Specifically, periods of adaptation should lead to higher connectivity in the Actual network than the Target network, since we expect productions to be more similar (and thus more well-connected) in Actual forms; we would expect connectivity across Data types to diverge at the point that word adaptation begins to take hold. Data type (Actual vs. Target) and corpus (English vs. French) were included as parametric terms, with Data type being the variable of interest. Network size and age were included as smooth terms, as well as by-subject and by-data type random smooths for the effect of age, which account for by-subject and by-data type differences in the data over time. 

To account for the fact that adjacent values (i.e. connectivity at month *n* and month *n+1*) are likely correlated, GAMM modelling includes an autocorrelation parameter; see REFs for full details. Additionally, the start point for each infant’s data (i.e. their first recording session) was indexed in the model. To test for an effect of data type, model comparisons were run using the
*compareML()* function from the *itsadug()* package [REFs]: the full model including the effect of data type and the by-data type random smooth was compared to a model without these terms. Because model summaries for GAMM smooths may be non-conservative (*Sóskuthy, 2017*), smooth plots will be observed alongside any significant effects to determine relevant trends in the data.

```{r GAMMs set up}

SWD_red$start.event <- SWD_red$session_ordinal == 1 

globalthresholds$start.event <- globalthresholds$threshold == 0.01

# create dummy variable for actual vs. target 

globalthresholds$IsActual <- (globalthresholds$data_type == "actual")*1

```

```{r GAMMs - mean k ~ data type}

meank.gamm.base <- bam(mean_k ~ 
                          data_type +
                          corpus +
                            s(numNodes, bs = "cr")  +
                          s(age, bs = "cr") +                       
                          s(age, by=Speaker, bs="cr"),
                        dat=subset(SWD_red, data_type %in% c("actual", "target")), method="ML")

rmeank <- start_value_rho(meank.gamm.base) 

meank.gamm.1 <- bam(mean_k ~ 
                      data_type +
                      corpus +
                      s(numNodes, bs = "cr")  +
                      s(age, bs = "cr") + 
                       s(age, data_type, bs="fs", m=1, k=2) + 
                      s(age, Speaker, bs="fs", m=1, k=9),  
                    dat=subset(SWD_red, data_type %in% c("actual", "target")), method = "ML", 
                     rho=rmeank, AR.start=subset(SWD_red, data_type %in% c("actual", "target"))$start.event)

meank.gamm.0 <- bam(mean_k ~ 
                      #data_type +
                      corpus +
                      s(numNodes, bs = "cr")  +
                      s(age, bs = "cr") +     
                     # s(age, data_type, bs="fs", m=1, k=2) + 
                      s(age, Speaker, bs="fs", m=1, k=9),  
                    dat=subset(SWD_red, data_type %in% c("actual", "target")), method = "ML", 
                    rho=rmeank, AR.start=subset(SWD_red, data_type %in% c("actual", "target"))$start.event)

meank.diff <- compareML(meank.gamm.1, meank.gamm.0)
meank.diff.prep <- meank.diff$table

meank.diff_summ <- summary(meank.diff.prep)

```

Model comparisons revealed a significant effect for data type on connectivity in the networks over time. See Table \@ref(tab:table-GAMM-outputs). Figure \@ref(fig:difference-plot-mean-k) shows the difference between Actual and Target connectivity over the course of development. The red line indicates periods of significant difference, showing that Actual vs. Target connectivity was significantly different throughout the period of analysis. However, the narrower difference in the earlier period of analysis (months 10-15, when differences in Estimate values are closer to 0) suggests that, during the earlier period of analysis, Target forms are as well-connected as Actual forms, suggesting a period of early word selection. 

```{r difference-plot-mean-k, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE,results='hide',fig.keep='all'}
plot_diff(meank.gamm.1, view="age", comp=list(data_type=c("target","actual")),
          # main = "Figure 3",
          # ylab = "Est. difference in scaled PAT values",
          xlab = "Age (months)",
          xlim = c(10,30),
          hide.label = TRUE)

cap <- sprintf("Difference smooth plot showing difference between connectivity (mean k) in Actual vs. Target forms from the GAMM model specified above. Shaded area shows 95%% confidence intervals, red line along x-axis indicates months in which
the difference between Actual and Target forms was significant.")
```
```{r phonological distance analysis - prep}

n_types <- nrow(comparison_summary)
```

Analyses of network structure changes over time thus appears to reflect the framework proposed by Vihman. To interrogate this further, we can also look more closely at the phonological distance between Actual and Target forms. This doesn't take into account any aspect of network structure *per se*, but instead looks directly at the measures that the network structures reported above have been derived from. 

In this final analysis, the raw phonological distance measures were extracted for each word in the data set. Since variability in production of a given word was high for each speaker, a mean phonological distance for each word type produced at each time-point was taken for each infant, leaving `r n_types` data points for analysis. As above, GAMMs were run to test the extent to which phonological distance differed as a function of age. In the framework proposed by Vihman, we would expect lower distances earlier on in production, as words are selected (and so Actual forms are more similar to Target forms) and higher distances later, as Target forms are adapted, and thus are realised in a more phonologically-distant way in their Actual form. 

Mean phonological distance for each word type in each month was included in the model as the dependent variable. Corpus was included as a parametric term, and age as a smooth term. By-subject random smooths were included for the effect of age. As above, an autocorrelation parameter was included in the model, and the first recording session for each infant was indexed in the model. 

```{r}
dist.gamm.base <- bam(dist_mean ~ 
                         corpus +
                          # s(session_ordinal, bs = "cr") +
                           s(age, bs = "cr")  +                     
                          s(age, by=Speaker, bs="cr"),
                        dat=comparison_summary, method="ML")

rdist <- start_value_rho(dist.gamm.base) 

dist.gamm.1 <- bam(dist_mean ~ 
                      corpus +
                     # s(session_ordinal, bs = "cr") +
                      s(age, bs = "cr")  +   
                      #s(session_ordinal, Speaker, bs="fs", m=1, k=9) +
                     s(age, Speaker, bs="fs", m=1, k=9),
                    dat=comparison_summary, method = "ML", 
                     rho=rdist, AR.start=comparison_summary$session_ordinal == 1)

dist.gamm.0 <- bam(dist_mean ~ 
                     corpus,
                     #s(session_ordinal, bs = "cr")  +   
                     # s(session_ordinal, Speaker, bs="fs", m=1, k=9) + 
                     #s(age, bs = "cr")  +   
                     #s(age, Speaker, bs="fs", m=1, k=9),  
                   dat=comparison_summary, method = "ML", 
                   rho=rdist, AR.start=comparison_summary$session_ordinal == 1)

dist.diff <- compareML(dist.gamm.1, dist.gamm.0)
dist.diff.prep <- dist.diff$table

dist.diff_summ <- summary(dist.diff.prep)

```
```{r GAMM output table, echo=FALSE, message=FALSE, warning=FALSE}

gamm.models.all <- rbind(meank.diff.prep, dist.diff.prep) 

gamm.models.all <- gamm.models.all %>%
  mutate(Model = fct_recode(Model,
                            "Connectivity ~ data type" = "meank.gamm.1",
                             "Phonological distance ~ age" = "dist.gamm.1"),
         p.value = ifelse(Sig. == "***", "<.001", p.value)) %>%
  filter(Difference > 0 ) %>%
  rename("Chi Sq" = "Difference")  %>% 
  unite(p, c(p.value, `Sig.`), sep = "", remove = FALSE)%>%
  dplyr::select(Model, Df, `Chi Sq`, p)

```

```{r table-GAMM-outputs, echo=FALSE, message=FALSE, warning=FALSE}
cap="Outputs from nested model comparisons of GAMMs testing the effect of data type on network connectivity (Connectivity ~ data type) and the effect of age on phonological distance (Phonological distance ~ age). Model comparisons compared full models against those without parametric and smooth terms that included the variable being tested."
kable(gamm.models.all, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c") %>%
    kable_styling()
```

Model comparisons between the full model and a model without the effect of age (in both smooth and random smooth terms) revealed that age had a significant effect on the data. See Table \@ref(tab:table-GAMM-outputs). This is plotted in Figure \@ref(fig:plotted-smooth-phon-distance), where the trajectory of phonological distance over time reveals some evidence of selection and adaptation. At first, phonological distance is high - infants' productions are not initially target-like. By around 15 months, however, distance 

```{r plotted-smooth-phon-distance, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE,results='hide',fig.keep='all'}

phonological.distance
cap <- sprintf("Smooth plot showing overall mean phonological distance between Actual and Target forms over time. Shaded area shows 95%% confidence interval, blue line indicates mean trajectory over time.")
```


## Simulated Networks

Finally, network graphs generated from the Target and Actual data of each corpus were compared to simulated small world and random networks of equivalent size to determine whether the data (the *Real* networks) differed from the *Simulated* networks. Recall that PAT-like network growth should reflect a small-world network growth structure. Two key components of small-world networks were compared: mean path length and clustering coefficient. PAT-like network growth (small world networks cannot tell us anything about PAQ-like growth) typically has a low mean path length and a high clustering coefficient; for both measures we would expect the Real data to differ significantly from the Simulated Erdős–Rényi (random) network, and to see no statistical difference between the Real network and the Simulated Watts-Strogatz (small-world) network. The two measures will be discussed in turn, for Target and Actual data from each corpus.

### Mean Path Length
Mean path length was calculated for each child's monthly networks using the *igraph()* package in R [@R-igraph]. For both Target and Actual data, an equivalent-sized Watts-Strogatz network was generated, and a single Erdős–Rényi network. Watts-Strogatz simulations match both the mean degree and the network size of the network in each month, so two separate networks were generated for Target and Actual data to reflect the different properties of each. Erdős–Rényi networks require only network size to be specified - as this is constant across Target and Actual data, only one such network was generated per month. 


