---
title: "NetworkGraphs"
author:
- name: Catherine E. Laing
  affiliation: '1'
  corresponding: yes
  address: Department of Language and Linguistic Science, University of York, Heslington, YO10 5DD.
  email: catherine.laing@york.ac.uk
authornote: |
 All code and associated data for this manuscript can be found at https://github.com/cathelaing/NetworkGraphs.
shorttitle: Network graphs of early phonological development
output:
  papaja::apa6_pdf: default
  #extra_dependencies: ["float"]
  #papaja::apa6_word: default
abstract: "ADD."
keywords: systematicity, phonological development, preferential attachment, networks analysis
#wordcount: "" 
bibliography: Systematicity.bib
#floatsintext: yes
figsintext: no
figurelist: yes
tablelist: no
footnotelist: no
linenumbers: no
numbersections: false
mask: no
draft: no
documentclass: apa6
header-includes:
-  \DeclareDelayedFloatFlavor{kableExtra}{table}
- \usepackage{tipa}
#- \newfontfamily\PF{Arial}
classoption: man
affiliation:
- id: '1'
  institution: University of York, York, UK
latex_engine: xelatex
---

```{r setup, include=FALSE}

source("prelims.R")
r_refs(file="r-references.bib")
#tinytex::install_tinytex()

my_citations <- cite_r(
  file="r-references.bib"
  , pkgs=c("tidyverse", "igraph", "papaja", "lmerTest")
  , withhold=FALSE
  , footnote=TRUE
)

# load files

SWD_red <- globalsmallworlddata[which(complete.cases(globalsmallworlddata[
  ,c('path_length', 'clust_coef_global', 'clust_coef_avg', 'mean_k')])),]

stat_sum_df <- function(fun, geom="crossbar", ...) {
  stat_summary(fun.data=fun, colour="red", geom=geom, width=0.2, ...)
}

source("NetworkGraphs-Figures.R")

```

Infants' early words are phonologically similar to one another, if not in the vocabulary items they choose to produce, but in the way they produce them. This has been well-documented in a number of previous studies [e.g. @waterson_child_1971; @szreder_acquisition_2013; @vihman_prosodic_2016], and can be clearly observed in datasets of early productions. For example, an inspection of Deuchar and Quay's [-@deuchar_bilingual_2000] record of their Spanish-English bilingual child's vocabulary acquisition shows that many of her earliest words are produced with an open CV syllable, and she produces a number of identical forms to refer to a range of different (though phonologically-similar) words. This suggests that infants may be drawing on a systematic approach to early productions, whereby a small subset of simple phonological forms are used to produce a range of more varied and phonologically-challenging adult targets. We would expect, therefore, that newly-acquired productions 'cluster together' with existing forms, with high phonological similarity between new words and existing words in the lexicon. This paper will draw on network graphs of the early vocabulary to determine how similar infants' words are to one another, and how this changes over time. 

Network analysis is an increasingly popular method of analysing lexical acquisition. Network models allow the analysis of connectivity within a system (in our case, the lexical or phonological system), and can track how that connectivity changes over time. In the case of language development, the nodes (individual items) in the network typically consist of words, and these are connected (or not) depending on how similar two nodes are in phonological or semantic space. Two words that are more similar to one another will be positioned closer together in the network, and less similar nodes further apart. Because this is a convenient way to think about language development over time, a number of studies have considered vocabulary acquisition within this framework. Analyses have considered infants acquiring their first language [e.g. @amatuni_semantic_2017; @fourtassi_growth_2020 ] and adults acquiring a novel language [e.g. @mak_evidence_2020; @siew_investigation_2020]. 

Systematicity in early phonological development is most comprehensively discussed in work by Vihman [e.g. @vihman_prosodic_2016; @vihman_phonological_2019; @vihman_emergence_2013; @vihman_phonological_2007]. In more than four decades of work, incorporating data from a large number of infants acquiring an impressive range of languages, Vihman demonstrates a clear systematicity in infants' path to target-like word production. From the initial 'surprisingly accurate' forms that appear in the first stages of word production, infants are shown to draw on what they know: they generally choose, for first production, words that are simple in their target phonological form, with consonants that are already familiar from the most common syllables of canonical babble [@mccune_early_2001]. These forms are, in Vihman's terms, *selected* for first word production owing to their easily-producible features. As the vocabulary grows, infant must necessarily acquire forms that do not contain such accessible phonological or segmental properties. Here we begin to see regression in the accuracy of early production, as infants systematically adapt forms to fit the most common structures and segments in their repertoire. When words are systematically altered to fit a dominant pattern in the child's output, these forms are said to be *adapted*. Systematicity is apparent not just in the earliest words, but across the trajectory of acquisition as infants deal with the challenges of early word production by relying on well-rehearsed output forms. Over the first months of lexical development at least, infants' productions of newly-acquired words are likely to match their productions of existing words in the lexicon.

In recent work [@laing_phonological_2023], I draw on network analysis to analyse systematicity in the developing lexicon. I show that in the first three years of life, infants' production of new words can be predicted based on the words they already produce. That is, a word is more likely to be acquired if it is phonologically similar to existing words in the productive repertoire, particularly when the new word is similar to a cluster of existing phonologically-similar forms in the output. This effect becomes stronger over time, suggesting that systematicity is more relevant to later word learning (at least, upto age 30 months) than in the first few months of word production. Moreover, the phonological properties of infants' word productions are more similar to one another than their adult target forms would suggest. These findings support the more fine-grained analyses presented by Vihman and colleagues.

A number of other studies have found consistent results when analysing early vocabulary development. Laing [-@laing_phonological_2023] drew on corpus data of fortnightly word production across nine infants; similar results have been observed by Kalinowski and colleagues [-@kalinowski_development_nodate], who draw on vocabulary norms from >1000 Norwegian infants taken longitudinally at up to six individual time-points. Systematicity was also identified in early word learning by Siew and Vitevitch [-@siew_investigation_2020], in an analysis of vocabulary norms of children aged 3-9 years acquiring English and Dutch. Fourtassi and colleagues [-@fourtassi_growth_2020], on the other hand, found no support for systematicity in their analysis of infants acquiring a range of 10 different languages, instead showing that salient properties of the input, rather than previously-learned phonological properties, predicted learning.

This previous work uses network growth algorithms to test whether learning can be predicted based on the words that infants already know or produce. This method works on the assumption that, if infants' early word acquisition and production is phonologically systematic, then it should be possible to predict learning based on the known words in the infant's existing lexicon. This is a compelling computational approach to observing systematicity in the developing lexicon, but does not give us a clear view into the extent to which early-acquired forms are produced in a phonologically similar way. That is, network growth models analyse connectivity (are two words similar, yes or no? if yes then they are connected in the network), rather than phonological distance (*how* similar are two words in the network?). This study expands on previous work, and builds on findings from Laing [-@laing_phonological_2023], by analysing network graphs of infants' early lexicons. This provides an insight into the properties of the network, including how densely-connected the network is, and the phonological distance between items in the network. It also allows us to make predictions about network properties over time that reflect word selection and adaptation. Following Laing [-@laing_phonological_2023], this paper will analyse infants' actual productions as well as the adult target forms, to test the extent to which systematicity is present in production, in terms of both the words infants select in early development, and how they produce them. 

## Research questions and predictions

This paper analyses network graphs instead of growth algorithms to look more closely at the phonological distance between individual words in the developing lexicon. In doing so, it attempts to address the following questions:

1. How systematic are early word productions, and (how) does this change over time?
2. Are the phases of word selection and adaptation identifiable in the dataset?

To test these questions, network graphs will be generated using the *igraph()* package [@R-igraph] in R [@R-base]. To address the first question, properties of the graphs will be analysed to determine 1) how closely connected individual words are to one another; 2) how dense the overall distribution of words is in the network; and 3) how/whether this changes over time. Following Vihman's work, and findings presented by Laing [-@laing_phonological_2023], it is expected that the early vocabulary will become increasingly systematic over time. This would be reflected in denser clusters of phonologically-similar forms and lower distance between words. Simulated networks will be used to compare the real networks against both highly systematic and random networks to determine the extent of systemacitity present in the data.

To address the second question, network graphs of infants' actual productions will be compared with those of the target form, to trace the 'target-likeness' of individual productions, and how this changes over time. Following Vihman once again, early word selection would be reflected in early similarities between Actual and Target network properties, as target forms are selected to match the structures and segments that infants are able to produce, meaning they should be produced with relative accuracy. Over time, Actual and Target forms are expected to diverge, such that Actual forms show more systematicity in the data than Target forms. Approaches used to test these predictions are outlined in detail below.


# Methods

## Data extraction and preparation

This study draws on the same data as that analysed by Laing [UR]. This was drawn from two corpora on PhonBank (https://phonbank.talkbank.org/): Providence [American English, @demuth_word-minimality_2006] and Lyon [French, @demuth_katherine_prosodically-conditioned_2008]. These were selected due to their equivalent data collection methods and the fact that the infants' productions, as well as the corresponding target forms, are phonetically transcribed. Nine infants' (5 English, 4 French, 4 boys overall) data were extracted using Phon [@hedlund_gregory_phon_2020], from the transcript with their first-recorded word to the final transcript taken at age 2;6. Infants were recorded in the home on a fortnightly basis, participating in naturalistic interactions with their caregivers. Two of the American infants were recorded weekly during some periods of data collection, but this is not an issue for this analysis since no between-child comparisons will be made. See Demuth et al. [-@demuth_word-minimality_2006] and Demuth and Tremblay [-@demuth_katherine_prosodically-conditioned_2008] for full details of data collection.

Extracted data was filtered to include only words featuring on the communicative development inventory (CDI) of the respective language, including all variants of a given form. For example, plurals were included alongside the singular noun form, and variable verb conjugations alongside their corresponding infinitive verb form. These data were used to create a network for each infant, whereby all words in a given month that hadn't been produced in previous months were included as new items in the network. When a word had been produced in previous months, it was not included. While this means that the data does not capture change in the production of a single form over time, it allows us to observe network growth at the point of acquisition for each word form. 

To determine the structure of the network, the first step was to create distance values between each word and each other word in the network. This was first done using a 'global' network of all forms produced by the infant up to the final session at 2;6, to create a large distance matrix for each infant that incorporated all word productions. Distance values were established using methods set out in Monaghan et al. [-@monaghan_measures_2010], using distinctive features to generate a set of phonetic values for each word that could then be compared with all other words (note that only consonants were analysed, given that vowels are highly variable in early production and also very difficult to transcribe accurately; [@donegan_normal_2013; @kent_what_2020]). Euclidean distance between the values of each word and each other word in each infant's global network was then used to determine how close/distant words were from one another. Often, infants produced multiple tokens of the same word type in a given month, often with high variability across tokens. Because it was not possible to generate networks with all tokens included (even with only single word types included, the final dataset for all nine infants includes over 5.5 million data points, once distance between each word and each other word is calculated), a mean value for each distinctive feature was established across tokens, meaning that each word's distinctive feature value represents the variability of the infant's production of a given word. This may not be a perfect measure, but it is more representative than taking, for example, the first instance of each word type.

Distance scores were generated between each word and each other word in each child's dataset, for both Target and Actual forms. These scores were then normalised, and a normalised distance of 0.25 was chosen to indicate connectivity. That is, words were said to be connected in the network if their distance score was 0.25 or less. This accounted for the lower quartile of connectivity across the dataset. See Supplementary Materials for an overview of how this measure was established.

```{r data overview}
types.corpus <- comparison_data %>%
  group_by(corpus, Speaker) %>%
  distinct(Gloss, .keep_all=T) %>%
  tally() %>% summarise(n=sum(n))

types <- comparison_data %>%
  group_by(Speaker) %>%
  distinct(Gloss, .keep_all=T) %>%
  tally() %>% summarise(n=sum(n))

tokens <- comparison_data %>%
  group_by(Gloss, Speaker) %>%
  tally() %>% ungroup() %>%
  summarise(mean_tok=mean(n),
            sd_tok=sd(n))

tokens.corpus <- comparison_data %>%
  group_by(Gloss, Speaker, corpus) %>%
  tally() %>% ungroup() %>%
  group_by(corpus) %>%
  summarise(mean_tok=mean(n),
            sd_tok=sd(n))

```

The final dataset includes `r round(types$n)` word types in total, with `r round(subset(types.corpus, corpus == "English")$n)` in the English corpus and `r round(subset(types.corpus, corpus == "French")$n)`) in the French corpus. On average, infants produced `r round(tokens$mean_tok)` tokens of each word type in a single session (SD = `r round(tokens$sd_tok)`; mean English = `r round(subset(tokens.corpus, corpus == "English")$mean_tok)`, SD = `r round(subset(tokens.corpus, corpus == "English")$sd_tok)`; mean French = `r round(subset(tokens.corpus, corpus == "French")$mean_tok)`, SD = `r round(subset(tokens.corpus, corpus == "French")$sd_tok)`). 

## Data analysis

### Network graphs

The prepared data was then used to generate a series of network graphs for each infant (for both Target and Actual data) using the *igraph()* package in R [@R-igraph]. One network was generated per month, for each month in the dataset, based on all words produced in the given month and all months prior. The network at time-point *n*+1 thus included all words at time-point *n*, plus all additional words produced for the first time at *n*+1. The *igraph()* package generates graphs that include all nodes (whether or not they are connected to other nodes[^1]), and measures the distance between all connected nodes, as well as the clustering of nodes in graphical space. 

[^1]: Recall that any two nodes that have a scaled phonological distance of >.25 will not be connected.

Two key variables will be explored through an analysis of network graphs: *mean path length* and *clustering coefficient*. Path length is a measure of distance between nodes, and mean path length indexes the average connectivity (of all connected nodes) within a network; by this measure, we would expect that systematicity in early phonological development would be reflected in low mean path length. Clustering coefficient is an indication of network density: a higher density of nodes in the network indicates denser clusters of similar forms; again, this is what we would expect to see in a network of early phonological development. See Goldbeck [-@golbeck_analyzing_2013] for a full overview of network structures and measures.

### Simulated networks

PAT-like networks should exhibit properties of prototypical "small-world" network growth, namely a low mean path length and a high clustering coefficient [@watts_collective_1998; @amaral_classes_2011; @steyvers_large-scale_2005]: words should be more densely connected, with shorter connections between words. To test this, mean path length and clustering coefficient values were generated for both the Target and Actual networks, as outlined below. Data were compared to the growth of a simulated small-world network, known as a Watts-Strogatz network [@watts_collective_1998]; if no statistical differences are observed between the real and simulated data over the trajectory of development, this would reflect strong systematicity in growth of the real network. The real data were also compared to a similarly-sized but randomly-generated network known as a Erdős–Rényi model. Similarly, if the real network grows in a systematic way, then we would expect the real data to differ significantly from the randomly-generated Erdős–Rényi network. To run these analyses, mean path length and clustering coefficient were calculated for each monthly graph, and then compared to the two kinds of simulated data, matched for network size: a Watts-Strogatz network (prototypical systematic network) and an Erdős–Rényi network (random network). Watts-Strogatz simulations were generated to match both the mean connectivity and the network size of the network in each month; Erdős–Rényi networks require only network size to be specified.

# Results

## RQ1: How systematic are early word productions, and (how) does this change over time?

To test RQ1, network graphs were compared to simulated small world and random networks of equivalent size to determine whether the data (the *Real* network) differed from the *Simulated* networks. Recall that systematic network growth, as predicted here, should reflect a small-world network growth structure. Two key components of these networks were compared: mean path length and clustering coefficient. Small-world networks typically have a low mean path length and a high clustering coefficient; for both measures we would expect the Real data to differ significantly from the Simulated Erdős–Rényi (random) network, and for the Real network to show similar properties to the Simulated Watts-Strogatz (small-world) network. Note that the extent of the expected statistical difference is not easy to predict here: if the Real network is very similar to the Watts-Strogatz network then no statistical difference would be expected, but this relies on the Real data being highly systematic, which may not be realistic. In order to fully understand the nature of the data, figures and model outputs will be inspected in relation to these predictions.

The two measures will be discussed in turn. Models include mean path length or average clustering coefficient as dependent variables, respectively, each with data type (Real vs. small-world vs. random), corpus (English vs. French) and age as fixed effects, and subject as a random effect with a by-subject random slope for the effect of age. Initial model comparisons showed that including network size to the model improved fit for the clustering coefficient data, but not for mean path length, so an age*network size interaction was included in this model only. 

### Mean Path Length
Mean path length was calculated for each child's monthly networks using the *igraph()* package in R [@R-igraph]. Equivalent-sized Watts-Strogatz and Erdős–Rényi networks were generated for comparison.  

```{r mean path length, message=FALSE, warning=FALSE, include=FALSE}

MPL <- lmerTest::lmer(path_length ~ data_type + corpus + age + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "WS_actual", "Erdos_Renyi")
                                                           ),
                                       REML=FALSE)
#summary(MPL)

MPL.0 <- lmerTest::lmer(path_length ~ corpus + age + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "WS_actual", "Erdos_Renyi")
                                                           ),
                                       REML=FALSE)

MPL_anova <- anova(MPL, MPL.0)

model.summary.MPL <- summary(MPL)

MPL_tab <- model.summary.MPL$coefficients %>%
  as.data.frame %>%
  rename(
    "beta"="Estimate"
     , "SE"="Std. Error"
     , "t"="t value"
     , "p"="Pr(>|t|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  ) %>%
  printnum(
    digits=c(3, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  #select(Effect, `beta`, `SE`, `t`, `p`) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `t`=as.numeric(`t`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p)) %>%
  mutate(Effect = fct_recode(Effect,
                             "Real vs. Watts-Strogatz" = "Data typeWS actual",
                             "Real vs. Erdős–Rényi" = "Data typeErdos Renyi",
                             "Corpus" = "CorpusFrench")) %>%
  dplyr::select(Effect, beta, SE, t, p)


```

Nested model comparisons revealed a significant effect for data type on mean path length. See Table \@ref(tab:table-model-output). As shown in Table \@ref(tab:table-real-sim), the Real data had a significantly lower mean path length than the random Simulated data, as predicted. However, the Real data also differed significantly from the small-world Simulated data, which had a significantly shorter mean path length than that of the Real data. Model outputs revealed no effect for corpus or age on the data. COntrary to preductions, there was no change in systematicity over time, at least in terms of mean distance between words. 

```{r clustering coefficient, message=FALSE, warning=FALSE, include=FALSE}

CC <- lmerTest::lmer(clust_coef_avg ~ data_type + corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "WS_actual", "Erdos_Renyi")
                                                           ),
                                       REML=FALSE)
#summary(CC)

CC.0 <- lmerTest::lmer(clust_coef_avg ~ corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "WS_actual", "Erdos_Renyi")
                                                           ),
                                       REML=FALSE)

CC_anova <- anova(CC, CC.0)

model.summary.CC <- summary(CC)

beta.val.interaction.CC <- model.summary.CC$coefficients %>% 
  as.data.frame %>% 
  tibble::rownames_to_column("Effect") %>%
  filter(Effect == "age:numNodes")

CC_tab <- model.summary.CC$coefficients %>%
  as.data.frame %>%
  rename(
    "beta"="Estimate"
     , "SE"="Std. Error"
     , "t"="t value"
     , "p"="Pr(>|t|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  ) %>%
  printnum(
    digits=c(3, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  #select(Effect, `beta`, `SE`, `t`, `p`) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `t`=as.numeric(`t`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p)) %>%
  mutate(Effect = fct_recode(Effect,
                             "Real vs. Watts-Strogatz" = "Data typeWS actual",
                             "Real vs. Erdős–Rényi" = "Data typeErdos Renyi",
                             "Corpus" = "CorpusFrench",
                             "Network size" = "NumNodes",
                             "Age * Network size" = "Age $\\times$ NumNodes")) %>%
  dplyr::select(Effect, beta, SE, t, p)

```

### Clustering coefficient
The same patterns were found when clustering coefficient was tested in the model. See Tables \@ref(tab:table-model-output) and \@ref(tab:table-real-sim). The Real data had a significantly higher clustering coefficient than the random Simulated data, but this was significantly lower than that of the small-world Simulated data. Again there was no effect for corpus on the data, and no effect of age in its own right, but network size, and its interaction with age, were found to be significant predictors of average clustering coefficient: clustering coefficient values decreased as network size increased, suggesting that systematicity became stronger in the data over time. The age * network size interaction was also found to be significant, such that with each additional month of age, the effect of network size on clustering coefficient decreased by `r round((beta.val.interaction.CC$Estimate)*100,3)`%.

### Actual vs. Target data
The differences between the Real data and the small-world Simulated data are difficult to interpret, given that there is no clear model of what phonological systematicity would look like in a highly systematic small-world network. To further interrogate systematicity within the data, network properties of the Real (Actual) data were compared to the Real Target data. Target data serves as an appropriate proxy for connectivity and clustering within a "standard" phonological network, albeit a network that is constrained by words produced in early acquisition, and further constrained by the fact that only a subset of these (i.e. CDI words) are included in the dataset. We would expect that mean path length and clustering coefficient would each show higher systematicity in the Actual network than the Target network[^2]. Basic model structure was the same as reported above, but with only Real data (Actual vs. Target) considered as a fixed effect. Initial model comparisons supported the inclusion of an age * network size interaction in both sets of models.

[^2]: Note that this result was observed for network growth models in Laing [UR], whereby the Actual network was found to be a better predictor of learning based on the known network of each child.

```{r data type - mean path length, message=FALSE, warning=FALSE, include=FALSE}

MPL.DT <- lmerTest::lmer(path_length ~ data_type + corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "target")
                                                           ),
                                       REML=FALSE)
#summary(MPL.DT)

MPL.DT.0 <- lmerTest::lmer(path_length ~ corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "target")
                                                           ),
                                       REML=FALSE)

MPL.DT_anova <- anova(MPL.DT, MPL.DT.0)

model.summary.MPL.DT <- summary(MPL.DT)

beta.val.interaction.MPL.DT <- model.summary.MPL.DT$coefficients %>% 
  as.data.frame %>% 
  tibble::rownames_to_column("Effect") %>%
  filter(Effect == "age:numNodes")

MPL.DT_tab <- model.summary.MPL.DT$coefficients %>%
  as.data.frame %>%
    rename(
    "beta"="Estimate"
     , "SE"="Std. Error"
     , "t"="t value"
     , "p"="Pr(>|t|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  ) %>%
  printnum(
    digits=c(3, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `t`=as.numeric(`t`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p)) %>%
  mutate(Effect = fct_recode(Effect,
                             "Actual vs. Target" = "Data typetarget",
                             "Real vs. Erdős–Rényi" = "Data typeErdos Renyi",
                             "Corpus" = "CorpusFrench",
                             "Network size" = "NumNodes",
                             "Age * Network size" = "Age $\\times$ NumNodes")) %>%
  dplyr::select(Effect, beta, SE, t, p)

```

There was a significant effect for data type on mean path length. See Table \@ref(tab:table-model-output). Model outputs revealed that Target data had a significantly higher mean path length than Actual data (see Table \@ref(tab:table-actual-target)). See Figure \@ref(fig:Figure-path-length-DT). This time there was also a significant effect for corpus; French data had a higher mean path length than English data. Both age and network size significantly affected mean path length, which increased as age/network size increased. The age * network size interaction was also significant, but this time the effect was negative, such that the effect of network size on mean path length decreased by `r round((beta.val.interaction.MPL.DT$Estimate)*100,3)`% with each additional month of age. 

```{r data type - clustering coefficient, message=FALSE, warning=FALSE, include=FALSE}

CC.DT <- lmerTest::lmer(clust_coef_avg ~ data_type + corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "target")
                                                           ),
                                       REML=FALSE)
#summary(CC.DT)

CC.DT.0 <- lmerTest::lmer(clust_coef_avg ~ corpus + age * numNodes + (1+age|Speaker),
                                             data=subset(SWD_red,
                                                             data_type %in% c("actual", "target")
                                                           ),
                                       REML=FALSE)

CC.DT_anova <- anova(CC.DT, CC.DT.0)

model.summary.CC.DT <- summary(CC.DT)

beta.val.interaction.CC.DT <- model.summary.CC.DT$coefficients %>% 
  as.data.frame %>% 
  tibble::rownames_to_column("Effect") %>%
  filter(Effect == "age:numNodes")

CC.DT_tab <- model.summary.CC.DT$coefficients %>%
  as.data.frame %>%
    rename(
    "beta"="Estimate"
     , "SE"="Std. Error"
     , "t"="t value"
     , "p"="Pr(>|t|)") %>%
  mutate(
    Effect=papaja:::beautify_terms(rownames(.))
  ) %>%
  printnum(
    digits=c(3, 2, 2, 3)
    , gt1=c(TRUE, TRUE, TRUE, TRUE)
    , zero=c(TRUE, TRUE, TRUE, TRUE)
  ) %>%
  mutate(beta=as.numeric(beta),
        SE=as.numeric(SE),
        `t`=as.numeric(`t`),
        `p`=as.numeric(`p`),
             p=scales::pvalue(p)) %>%
  mutate(Effect = fct_recode(Effect,
                             "Actual vs. Target" = "Data typetarget",
                             "Real vs. Erdős–Rényi" = "Data typeErdos Renyi",
                             "Corpus" = "CorpusFrench",
                             "Network size" = "NumNodes",
                             "Age * Network size" = "Age $\\times$ NumNodes"))%>%
  dplyr::select(Effect, beta, SE, t, p)

```

The effect of data type on clustering coefficient was also significant. Mean clustering coefficient was significantly lower in Target vs. Actual data. See Figure \@ref(fig:Figure-clust-coef-DT). It was also lower in French compared with English data. Mean clustering coefficient decreased as age and network size increased (indicating increased systematicity over time); the age * network size interaction was significant, such that the effect of network size on clustering coefficient decreased by `r round((beta.val.interaction.CC.DT$Estimate)*100,3)`% with each additional month of age. 

```{r model outputs, include=FALSE}

table.model.output <- rbind(MPL_anova, MPL.DT_anova, CC_anova, CC.DT_anova) %>%
  rownames_to_column(var="Model") %>%
  filter(Chisq > 0) %>%
  rename(#"PA Df"="Df",
         #"PA Chisq"="Chisq",
         "p"=`Pr(>Chisq)`) %>%
  mutate(Model=fct_recode(Model,
                           "Mean Path Length (Real vs. Simulated)"="MPL",
                            "Clustering Coefficient (Real vs. Simulated)"="CC",
                            "Mean Path Length (Actual vs. Target)"="MPL.DT",
                            "Clustering Coefficient (Actual vs. Target)"="CC.DT"),
             p=scales::pvalue(p)) %>%
  dplyr::select(Model, `Df`, `Chisq`, `p`)

add_data1 <- data.frame(Effect = "Network size", beta = NA, SE = NA, t = NA, p = NA, row.names = "added")
add_data2 <- data.frame(Effect = "Age * Network size", beta = NA, SE = NA, t = NA, p = NA, row.names = "added")

MPL_tab <- bind_rows(MPL_tab, add_data1, add_data2)

real_v_sim <- cbind(MPL_tab, CC_tab)
rownames(real_v_sim) <- NULL
actual_v_target <- cbind(MPL.DT_tab, CC.DT_tab)
rownames(actual_v_target) <- NULL


actual_v_target[6] <- NULL
real_v_sim[6] <- NULL

```

```{r table-model-output, echo=F, message=FALSE, warning=FALSE, comment=F, results="asis"}
cap="Outputs from nested model comparisons testing the effect of data type (Real vs. Simulated and Actual vs. Target on mean path length and clustering coefficient."
knitr::kable(table.model.output, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c") %>%
  kable_styling()%>%
  row_spec(4, hline_after=T)

```

```{r table-real-sim, echo=F, message=FALSE, warning=FALSE, comment=F, results="asis"}
cap="Outputs from linear regression models testing comparisons of Real vs. Simulated data on mean path length and clustering coefficient."
knitr::kable(real_v_sim, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c") %>%
  add_header_above(c(" "=1, "Mean path length"=4, "Clustering coefficient"=4)) %>%
    kable_styling()
```

```{r table-actual-target, echo=F, message=FALSE, warning=FALSE, comment=F, results="asis"}
cap="Outputs from linear regression models testing comparisons of Actual vs. Target data on mean path length and clustering coefficient."
knitr::kable(actual_v_target, "latex", booktabs=T, longtable=T, caption=cap, digits=2, align="c") %>%
  add_header_above(c(" "=1, "Mean path length"=4, "Clustering coefficient"=4)) %>%
    kable_styling()
```

```{r Figure-path-length-DT, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE}
plot(path_length_plot_DT)
cap <- sprintf("Change in mean path length over time, in Actual vs. Target data. Coloured lines represent Data type; coloured bands represent 95%% CIs.")
```

```{r Figure-path-length-all, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE}
plot(path_length_plot)
cap <- sprintf("Change in mean path length over time, in Real data (Actual) compared with Simulated small-world (Watts-Strogatz) and random (Erdős–Rényi) networks. Coloured lines represent Data type; coloured bands represent 95%% CIs.")
```

```{r Figure-clust-coef-DT, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE}
plot(clust_coef_plot_DT)
cap <- sprintf("Change in mean clustering coefficient over time, in Actual vs. Target data. Coloured lines represent Data type; coloured bands represent 95%% CIs.")
```

```{r Figure-clust-coef-all, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE}
plot(clust_coef_plot)
cap <- sprintf("Change in mean clustering coefficient over time, in Real data (Actual) compared with Simulated small-world (Watts-Strogatz) and random (Erdős–Rényi) networks. Coloured lines represent Data type; coloured bands represent 95%% CIs.")
```


## RQ2. Is there evidence of word selection and adaptation in the dataset?

To address the second research question, the phonological distance between target and actual forms was taken as a proxy of word selection and adaptation. That is, if a word is produced in a target-like way (i.e. assumed to be selected[^3]), then the phonological distance between the Target form and the way it is produced (Actual form) should be low. The opposite is true for adapted forms, as we expect, by definition, a non-target-like production and thus a higher distance between Target and Actual form. This measure is not perfect, but coding selected/adapted forms in the data would otherwise have to be done by hand, which is not feasible across such a large dataset. Following Vihman's [REF] framework, we would expect low distance been Actual and Target forms earlier on in development, and higher distance later. To test this, I drew on generalized additive mixed effects models (GAMMs), since these allow the analysis of non-linear change over time, and can account for statistical differences between two non-linear trajectories of data that may differ in non-linear ways [@soskuthy_generalised_2017; @wieling_analyzing_2018].

[^3]: though note that, while a selected form is, by definition, target-like in phonological form, a target-like form isn't necessarily a selected form.

First, generalised linear mixed effects models, or GAMMs, were used to examine connectivity of the infants' Actual and Target networks and how these changed over time. These were run using the *mgcv()* package in R [@R-mgcv_a]. These models analyse the extent to which the two networks differ (or not) from one another across infants, and how this changes non-linearly month-by-month. Fixed effects in the model can include parametric terms, as is typical in regression modelling, and also *smooth terms*, or non-linear fixed effects. Much like mixed-effects linear models, GAMMs can account for random effects in the data; in this case by-subject random effects were included through the addition of *random smooths* in the model.

The model tested number of connections in the network (*mean k*) as the dependent variable, working on the assumption that connectivity in the Target vs. Actual networks would be similar during periods of word selection, and would differ during periods of adaptation. Specifically, periods of adaptation should lead to higher connectivity in the Actual network than the Target network, since we expect productions to be more similar (and thus more well-connected) in Actual forms; we would expect connectivity across data types to diverge at the point that word adaptation begins to take hold. Data type (Actual vs. Target) and corpus (English vs. French) were included as parametric terms, with data type being the variable of interest in the model. Network size and age were included as smooth terms, as well as by-subject and by-data type random smooths for the effect of age, which account for by-subject and by-data type differences in the data over time. 

To account for the fact that adjacent values (i.e. connectivity at month *n* and month *n+1*) are likely correlated, GAMM modelling includes an autocorrelation parameter; see Sóskuthy [-@soskuthy_generalised_2017] and Wieling [-@wieling_analyzing_2018] for full details. Additionally, the start point for each infant’s data (i.e. their first recording session) was indexed in the model. To test for an effect of data type, model comparisons were run using the *compareML()* function from the *itsadug()* package [@R-itsadug]: the full model including the effect of data type and the by-data type random smooth was compared to a model without these terms. Because model summaries for GAMM smooths may be non-conservative (*Sóskuthy, 2017*), smooth plots will be observed alongside any significant effects to determine relevant trends in the data.

```{r GAMMs set up}

SWD_red$start.event <- SWD_red$session_ordinal == 1 

globalthresholds$start.event <- globalthresholds$threshold == 0.01

# create dummy variable for actual vs. target 

globalthresholds$IsActual <- (globalthresholds$data_type == "actual")*1

```

```{r GAMMs - mean k ~ data type}

meank.gamm.base <- bam(mean_k ~ 
                          data_type +
                          corpus +
                            s(numNodes, bs = "cr")  +
                          s(age, bs = "cr") +                       
                          s(age, by=Speaker, bs="cr"),
                        dat=subset(SWD_red, data_type %in% c("actual", "target")), method="ML")

rmeank <- start_value_rho(meank.gamm.base) 

meank.gamm.1 <- bam(mean_k ~ 
                      data_type +
                      corpus +
                      s(numNodes, bs = "cr")  +
                      s(age, bs = "cr") + 
                       s(age, data_type, bs="fs", m=1, k=2) + 
                      s(age, Speaker, bs="fs", m=1, k=9),  
                    dat=subset(SWD_red, data_type %in% c("actual", "target")), method = "ML", 
                     rho=rmeank, AR.start=subset(SWD_red, data_type %in% c("actual", "target"))$start.event)

meank.gamm.0 <- bam(mean_k ~ 
                      #data_type +
                      corpus +
                      s(numNodes, bs = "cr")  +
                      s(age, bs = "cr") +     
                     # s(age, data_type, bs="fs", m=1, k=2) + 
                      s(age, Speaker, bs="fs", m=1, k=9),  
                    dat=subset(SWD_red, data_type %in% c("actual", "target")), method = "ML", 
                    rho=rmeank, AR.start=subset(SWD_red, data_type %in% c("actual", "target"))$start.event)

meank.diff <- compareML(meank.gamm.1, meank.gamm.0)
meank.diff.prep <- meank.diff$table

meank.diff_summ <- summary(meank.diff.prep)

```

Model comparisons revealed a significant effect for data type on connectivity in the networks over time. See Table \@ref(tab:table-GAMM-outputs). Figure \@ref(fig:difference-plot-mean-k) shows the difference between Actual and Target connectivity over the course of development. The red line indicates periods of significant difference, showing that Actual vs. Target connectivity was significantly different throughout the period of analysis; Actual forms were always more well-connected than Target forms. This contrasts with the expectations set out above. However, the narrower difference between months 10-15, when differences in Estimate values are closer to 0, supports the expectation that Target and Actual forms are more similar earlier on in development, implying that word selection takes place earlier on in the data, with some words being produced in a more target-like way than others. 

```{r difference-plot-mean-k, echo=FALSE, fig.cap=cap, fig.pos='H', message=FALSE, warning=FALSE,results='hide',fig.keep='all'}
plot_diff(meank.gamm.1, view="age", comp=list(data_type=c("target","actual")),
          # main = "Figure 3",
          # ylab = "Est. difference in scaled PAT values",
          xlab = "Age (months)",
          xlim = c(10,30),
          hide.label = TRUE)

cap <- sprintf("Difference smooth plot showing difference between connectivity (mean k) in Actual vs. Target forms from the GAMM model specified above. Shaded area shows 95%% confidence intervals, red line along x-axis indicates months in which
the difference between Actual and Target forms was significant.")
```

# Discussion


